"""
============================================
YASAA VISION - Vision Analysis Node (GÃ¶zcÃ¼)
============================================
Bu dÃ¼ÄŸÃ¼m, kullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi el fotoÄŸrafÄ±nÄ±
GPT-4o Vision modeli ile analiz eder.

GÃ¶rev:
- FotoÄŸrafÄ±n el olup olmadÄ±ÄŸÄ±nÄ± kontrol et
- El ise teknik analiz yap (Ã§izgiler, tepeler, parmaklar)
- Kesinlikle YORUM yapma, sadece GÃ–ZLEM yap

Ã‡Ä±ktÄ±:
- is_hand_detected: El tespit edildi mi?
- visual_analysis_report: Teknik analiz raporu
============================================
"""

# ============================================
# IMPORTS - Gerekli KÃ¼tÃ¼phaneler
# ============================================
import os                                      # Environment deÄŸiÅŸkenleri iÃ§in
import logging                                 # Profesyonel loglama
from typing import Dict, Any                   # Type hints iÃ§in

from dotenv import load_dotenv                 # .env dosyasÄ± okuma
from langchain_openai import ChatOpenAI        # GPT-4o modeli
from langchain_core.messages import HumanMessage  # Mesaj formatÄ±

# Kendi modÃ¼llerimiz
from app.agent.state import AgentState


# ============================================
# LOGGING AYARLARI
# ============================================
# Bu modÃ¼l iÃ§in Ã¶zel logger oluÅŸtur
logger = logging.getLogger(__name__)


# ============================================
# ENVIRONMENT DEÄÄ°ÅKENLERÄ°
# ============================================
# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# --- API AnahtarÄ± ---
OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

# --- Model AyarlarÄ± ---
VISION_MODEL: str = os.getenv("VISION_MODEL", "gpt-4o")
VISION_MAX_TOKENS: int = int(os.getenv("VISION_MAX_TOKENS", "1000"))


# ============================================
# MODEL BAÅLATMA
# ============================================

def _get_vision_llm() -> ChatOpenAI:

    if not OPENAI_API_KEY:
        raise ValueError("âŒ OPENAI_API_KEY .env dosyasÄ±nda bulunamadÄ±!")

    return ChatOpenAI(
        model=VISION_MODEL,
        api_key=OPENAI_API_KEY,
        max_tokens=VISION_MAX_TOKENS
    )


# ============================================
# VISION PROMPT ÅABLONU
# ============================================
# Bu prompt GPT-4o'ya "neye bakacaÄŸÄ±nÄ±" sÃ¶yler
# DÄ°KKAT: Yorum yapma, sadece gÃ¶zlem yap!

VISION_ANALYSIS_PROMPT: str = """
**ROLE:** Expert Chiromancy (Palmistry) Morphologist.

**TASK:** Analyze the user's hand image accurately and objectively.

**OUTPUT FORMAT:**
Please extract and describe these technical details in a structured way:

1. **HAND SHAPE:**
   - Type: (Square, Spatulate, Conic, Psychic, Philosophic, Elementary, Mixed)
   - Reasoning: (Based on palm width vs finger length ratio)

2. **PRIMARY LINES:**
   - **Life Line:** 
     * Length: (Long/Medium/Short)
     * Depth: (Deep/Medium/Faint)  
     * Curvature: (Widely curved around Venus / Straight / Close to thumb)
     * Special marks: (Islands, breaks, forks, branches - if any)

   - **Head Line:**
     * Direction: (Sloping toward Moon / Straight across / Rising toward fingers)
     * Length: (Reaches Mercury / Stops at Apollo / Short)
     * Fork at end: (Yes/No)

   - **Heart Line:**
     * Termination: (Under Jupiter / Between Jupiter-Saturn / Under Saturn)
     * Curvature: (Curved upward / Straight / Curved downward)
     * Depth: (Deep/Medium/Faint)

3. **MOUNTS (Prominence Level: Flat/Normal/Raised/Padded):**
   - Mount of Venus (thumb base)
   - Mount of Jupiter (under index finger)
   - Mount of Saturn (under middle finger)
   - Mount of Apollo (under ring finger)
   - Mount of Mercury (under little finger)
   - Mount of Moon (opposite thumb, lower palm)

4. **FINGERS:**
   - Thumb setting: (High/Medium/Low on palm)
   - Finger tips: (Pointed/Conic/Square/Spatulate)
   - Notable features: (Long/short fingers, gaps between fingers)

**CRITICAL INSTRUCTIONS:**
- Do NOT interpret meanings (e.g., "You will be rich", "You will travel")
- Do NOT give advice or predictions
- ONLY describe physical features you observe
- If the image is NOT a clear hand photo, respond with exactly: "NOT_A_HAND"
- If image quality is poor but it's a hand, do your best and note "LOW_QUALITY"
"""


# ============================================
# ANA NODE FONKSÄ°YONU
# ============================================

def vision_analysis_node(state: AgentState) -> Dict[str, Any]:
    """
    KullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi el fotoÄŸrafÄ±nÄ± analiz eder.

    Bu fonksiyon LangGraph tarafÄ±ndan Ã§aÄŸrÄ±lÄ±r.
    State'i alÄ±r, gÃ¶rsel analiz yapar, sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r.

    Args:
        state: Mevcut graph state'i (AgentState)

    Returns:
        Dict[str, Any]: State gÃ¼ncellemeleri
            - is_hand_detected: El tespit edildi mi?
            - visual_analysis_report: Teknik rapor (veya None)
            - error_message: Hata mesajÄ± (veya None)

    Flow:
        1. State'den resim verisini al
        2. Resim yoksa atla
        3. GPT-4o'ya gÃ¶nder
        4. Sonucu parse et
        5. State gÃ¼ncellemelerini dÃ¶ndÃ¼r
    """
    logger.info("--- ğŸ‘ï¸ GÃ–ZCÃœ NODE: FotoÄŸraf Analiz Ediliyor... ---")

    # ==========================================
    # ADIM 1: Resim Verisini Al
    # ==========================================

    image_data = state.get("user_image_bytes")

    if not image_data:
        logger.warning("   âš ï¸ Resim bulunamadÄ±, gÃ¶rsel analiz atlanÄ±yor.")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": None
        }

    logger.info(f"   ğŸ“¸ Resim verisi alÄ±ndÄ± ({len(image_data)} karakter)")

    # ==========================================
    # ADIM 2: GPT-4o Vision'Ä± HazÄ±rla
    # ==========================================

    try:
        llm = _get_vision_llm()
        logger.info(f"   ğŸ¤– Model yÃ¼klendi: {VISION_MODEL}")
    except ValueError as e:
        logger.error(f"   âŒ Model yÃ¼kleme hatasÄ±: {e}")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": "Sistem hatasÄ± oluÅŸtu, lÃ¼tfen tekrar deneyin."
        }

    # ==========================================
    # ADIM 3: MesajÄ± HazÄ±rla ve GÃ¶nder
    # ==========================================
    # LangChain formatÄ±nda multimodal mesaj oluÅŸtur

    message = HumanMessage(
        content=[
            # Metin kÄ±smÄ±: Prompt

            {
                "type": "text",
                "text": VISION_ANALYSIS_PROMPT
            },
            # GÃ¶rsel kÄ±smÄ±: Base64 encoded resim
            {
                "type": "image_url",
                "image_url": {
                    "ur": f"data:image/jpeg;base64,{image_data}"
                }
            },
        ]
    )

    # ==========================================
    # ADIM 4: API Ã‡aÄŸrÄ±sÄ±
    # ==========================================

    try:
        logger.info("   ğŸ”„ GPT-4o Vision API Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±yor...")
        response = llm.invoke([message])
        analysis = response.content
        logger.info("   âœ… API yanÄ±tÄ± alÄ±ndÄ±")

    except Exception as e:
        # API hatasÄ± (rate limit, network, vb.)
        logger.error(f"   âŒ Vision API hatasÄ±: {e}")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": "FotoÄŸrafÄ± analiz edemedim, tekrar dener misin kuzum?"
        }

    # ==========================================
    # ADIM 5: Sonucu DeÄŸerlendir
    # ==========================================

    # Durum 1: El deÄŸil
    if "NOT_A_HAND" in analysis:
        logger.warning("   âŒ GÃ¶nderilen fotoÄŸraf el deÄŸil")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": "Kuzum bu el fotoÄŸrafÄ± deÄŸil gibi gÃ¶rÃ¼nÃ¼yor. "
                             "AvuÃ§ iÃ§ini dÃ¼zgÃ¼nce gÃ¶steren bir fotoÄŸraf atar mÄ±sÄ±n?"
        }

    # Durum 2: DÃ¼ÅŸÃ¼k kalite ama el
    if "LOW_QUALITY" in analysis:
        logger.warning("   âš ï¸ DÃ¼ÅŸÃ¼k kaliteli el fotoÄŸrafÄ±")
        # Yine de analize devam et, ama not dÃ¼ÅŸ
        analysis = analysis + "\n\n[NOT: FotoÄŸraf kalitesi dÃ¼ÅŸÃ¼k, analiz kÄ±sÄ±tlÄ± olabilir]"

    # Durum 3: BaÅŸarÄ±lÄ± analiz
    logger.info("   âœ… El fotoÄŸrafÄ± baÅŸarÄ±yla analiz edildi")
    logger.debug(f"   ğŸ“ Analiz Ã¶nizleme: {analysis[:200]}...")

    return {
        "is_hand_detected": True,
        "visual_analysis_report": analysis,
        "error_message": None
    }


# ============================================
# TEST FONKSÄ°YONU
# ============================================
def _test_vision_node():
    """
    Vision node'u test etmek iÃ§in yardÄ±mcÄ± fonksiyon.

    KullanÄ±m:
        python -m app.agent.nodes.vision_node
    """
    import base64

    print("=" * 50)
    print("ğŸ‘ï¸ Vision Node Test")
    print("=" * 50)

    # Test iÃ§in Ã¶rnek bir state oluÅŸtur (resim olmadan)
    test_state: AgentState = {
        "messages": [],
        "user_image_bytes": None,  # Test iÃ§in resim yok
        "visual_analysis_report": None,
        "retrieved_documents": [],
        "final_response": None,
        "is_hand_detected": False,
        "error_message": None
    }

    print("\nğŸ“ Test 1: Resim olmadan Ã§aÄŸÄ±r")
    result = vision_analysis_node(test_state)
    print(f"   SonuÃ§: {result}")

    print("\n" + "=" * 50)
    print("âœ… Test tamamlandÄ±!")
    print("=" * 50)
    print("\nğŸ’¡ GerÃ§ek bir el fotoÄŸrafÄ± ile test etmek iÃ§in:")
    print("   1. Bir el fotoÄŸrafÄ±nÄ± base64'e Ã§evirin")
    print("   2. test_state['user_image_bytes'] = base64_data")
    print("   3. vision_analysis_node(test_state) Ã§aÄŸÄ±rÄ±n")


# ============================================
# MODÃœL DOÄRUDAN Ã‡ALIÅTIRILIRSA TEST YAP
# ============================================
if __name__ == "__main__":
    # Logging'i aktif et
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Testi Ã§alÄ±ÅŸtÄ±r
    _test_vision_node()


