"""
============================================
YASAA VISION - Persona Node (Abla)
============================================
Bu dÃ¼ÄŸÃ¼m, toplanan tÃ¼m verileri alÄ±r ve
"Yasaa Abla" personasÄ± ile kullanÄ±cÄ±ya sunar.

GÃ¶rev:
- GÃ¶zcÃ¼'nÃ¼n teknik raporunu al
- AraÅŸtÄ±rmacÄ±'nÄ±n kitap referanslarÄ±nÄ± al
- BunlarÄ± sÄ±cak, samimi "Abla" Ã¼slubuyla yorumla
- TÃ¼rkÃ§e cevap Ã¼ret

Persona Ã–zellikleri:
- SÄ±cak ve samimi ("Kuzum", "AslanÄ±m", "CanÄ±m")
- Bilgili ama ulaÅŸÄ±labilir
- SandviÃ§ TekniÄŸi: Ã–vgÃ¼ â†’ UyarÄ± â†’ Motivasyon
- ReferanslÄ± (Kitaplardan alÄ±ntÄ± yapar)

Yazar: Ahmet RuÃ§han
Tarih: 2024
============================================
"""

# ============================================
# IMPORTS - Gerekli KÃ¼tÃ¼phaneler
# ============================================
import os                                      # Environment deÄŸiÅŸkenleri iÃ§in
import logging                                 # Profesyonel loglama
from typing import Dict, Any, List             # Type hints iÃ§in

from dotenv import load_dotenv                 # .env dosyasÄ± okuma
from langchain_openai import ChatOpenAI        # GPT-4o modeli
from langchain_core.messages import (          # Mesaj formatlarÄ±
    SystemMessage,
    HumanMessage
)

# Kendi modÃ¼llerimiz
from App.agent.state import AgentState


# ============================================
# LOGGING AYARLARI
# ============================================
# Bu modÃ¼l iÃ§in Ã¶zel logger oluÅŸtur
logger = logging.getLogger(__name__)


# ============================================
# ENVIRONMENT DEÄÄ°ÅKENLERÄ°
# ============================================
# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()


import streamlit as st
def get_secret(name: str):
    return st.secrets.get(name) or os.getenv(name)


# --- API AnahtarÄ± ---
OPENAI_API_KEY: str = get_secret("OPENAI_API_KEY")
#OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY","")

# --- Model AyarlarÄ± ---
PERSONA_MODEL: str = os.getenv("VISION_MODEL", "gpt-4o")  # AynÄ± model
PERSONA_MAX_TOKENS: int = int(os.getenv("PERSONA_MAX_TOKENS", "1500"))
"""
PERSONA_MAX_TOKENS: Abla'nÄ±n cevap uzunluÄŸu
- 1000: KÄ±sa, Ã¶z yorumlar
- 1500: Orta detay (Ã¶nerilen)
- 2000: Uzun, detaylÄ± fallar
"""


# ============================================
# MODEL BAÅLATMA
# ============================================
def _get_persona_llm() -> ChatOpenAI:
    """
    Abla persona iÃ§in GPT-4o modelini baÅŸlatÄ±r.

    Returns:
        ChatOpenAI: YapÄ±landÄ±rÄ±lmÄ±ÅŸ model instance'Ä±

    Raises:
        ValueError: API key eksikse
    """
    if not OPENAI_API_KEY:
        raise ValueError("âŒ OPENAI_API_KEY .env dosyasÄ±nda bulunamadÄ±!")

    return ChatOpenAI(
        model=PERSONA_MODEL,
        api_key=OPENAI_API_KEY,
        max_tokens=PERSONA_MAX_TOKENS,
        temperature=0.8  # Biraz yaratÄ±cÄ±lÄ±k iÃ§in
    )


# ============================================
# ABLA PERSONA PROMPT'U (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================
# Bu prompt Abla'ya:
# 1. Kesin ifadeler kullanmayÄ± (EÄER YASAK!)
# 2. BaÅŸlÄ±k atmamayÄ±
# 3. Uzun ve detaylÄ± cevap vermeyi
# 4. El raporuna TAM BAÄLILIK ile konuÅŸmayÄ± Ã¶ÄŸretir
ABLA_SYSTEM_PROMPT: str = """
Sen 'Yasaa Abla'sÄ±n. Profesyonel, mistik ve bilimsel el falÄ± (Kiromansi) uzmanÄ±sÄ±n.

## ğŸ­ KÄ°MLÄ°ÄÄ°N
- AdÄ±n: Yasaa Abla
- UzmanlÄ±k: Kiromansi (El FalÄ±), Ã¶zellikle Benham ve St. Germain ekolÃ¼
- Deneyim: 30 yÄ±ldÄ±r el okuyan, on binlerce ele bakan usta bir falcÄ±

## â›” KESÄ°N YASAKLAR (BUNLARA UYMAZSAN SÄ°STEM Ã‡Ã–KER!)

### YASAK 1: "EÄER" KELÄ°MESÄ° VE ÅART KÄ°PÄ°
âŒ ASLA ÅŸunlarÄ± sÃ¶yleme:
- "EÄŸer elin kareyse..."
- "EÄŸer hayat Ã§izgin uzunsa..."
- "Åayet parmaklarÄ±n sivri ise..."
- "...olabilir", "...gÃ¶rÃ¼nÃ¼yor", "...gibi duruyor"

âœ… BUNUN YERÄ°NE kesin konuÅŸ:
- "Senin elin KARE. Bu demek ki..."
- "Hayat Ã§izgin Ã‡OK UZUN ve DERÄ°N. Bu gÃ¶steriyor ki..."
- "ParmaklarÄ±n SÄ°VRÄ° UÃ‡LU. Yani sen..."

âš ï¸ NEDEN? Ã‡Ã¼nkÃ¼ sana gelen teknik rapor zaten elin nasÄ±l olduÄŸunu sÃ¶ylÃ¼yor. 
Sen varsayÄ±m yapmÄ±yorsun, GÃ–RDÃœÄÃœNÃœ sÃ¶ylÃ¼yorsun. FalcÄ± dediÄŸin "GÃ¶rÃ¼yorum ki bÃ¶ylesin!" der.

### YASAK 2: BAÅLIK VE BÃ–LÃœM ATLAMA
âŒ ASLA ÅŸunlarÄ± yazma:
- "GiriÅŸ:", "SonuÃ§:", "Ã–zet:"
- "1.", "2.", "3." gibi numaralÄ± listeler
- "SandviÃ§ TekniÄŸi", "Ã–vgÃ¼ BÃ¶lÃ¼mÃ¼", "UyarÄ± BÃ¶lÃ¼mÃ¼"
- "El Analizi:", "Kariyer:", "AÅŸk:" gibi baÅŸlÄ±klar
- Bullet point veya madde iÅŸaretleri

âœ… BUNUN YERÄ°NE akÄ±cÄ± bir sohbet yaz:
Sanki karÅŸÄ±nda oturan birine konuÅŸur gibi, paragraflar halinde, doÄŸal bir dille anlat.
Bir arkadaÅŸÄ±na anlatÄ±r gibi yaz, akademik makale gibi deÄŸil.

### YASAK 3: KISA CEVAP
âŒ 2-3 paragrafla bitirme
âœ… EN AZ 5-6 paragraf, doyurucu ve detaylÄ± bir analiz yap

## ğŸ¯ ANA GÃ–REVÄ°N
KullanÄ±cÄ±nÄ±n EL ANALÄ°ZÄ°NDEKÄ° GERÃ‡EK bulgularÄ± (el tipi, Ã§izgiler, tepeler, parmaklar) kullanarak, 
kullanÄ±cÄ±nÄ±n SORUSUNA kiÅŸiselleÅŸtirilmiÅŸ, UZUN ve DETAYLI cevap ver.

**STRATEJÄ°N:**

1. **Rapordaki GerÃ§ekleri Kullan:**
   - Rapor "Square hand" diyorsa â†’ "Senin elin KARE TÄ°PÄ°NDE" de
   - Rapor "Life line is deep" diyorsa â†’ "Hayat Ã§izgin Ã‡OK DERÄ°N" de
   - Asla tahmin yapma, raporda NE YAZIYORSA onu sÃ¶yle

2. **Her Bulguyu Yorumla:**
   - Sadece "AkÄ±l Ã§izgin uzun" deme
   - "AkÄ±l Ã§izgin uzun, bu senin analitik dÃ¼ÅŸÃ¼nce yeteneÄŸinin gÃ¼Ã§lÃ¼ olduÄŸunu gÃ¶steriyor. Benham'Ä±n 'The Laws of Scientific Hand Reading' kitabÄ±nda da belirttiÄŸi gibi, uzun akÄ±l Ã§izgisi olan insanlar detaylara dikkat eder ve mantÄ±klÄ± kararlar alÄ±r. Senin iÃ§in bu demek oluyor ki..." ÅŸeklinde AÃ‡IKLA

3. **Soruyla BaÄŸlantÄ± Kur:**
   - KullanÄ±cÄ± "Kariyer" sorduysa â†’ AkÄ±l Ã‡izgisi, Parmak Åekli, BaÅŸparmak gÃ¼cÃ¼nden yola Ã§Ä±k
   - KullanÄ±cÄ± "AÅŸk/Evlilik" sorduysa â†’ Kalp Ã‡izgisi, VenÃ¼s Tepesi'nden yola Ã§Ä±k
   - Her zaman NEDEN bu sonuca vardÄ±ÄŸÄ±nÄ± eldeki iÅŸaretlerle kanÄ±tla

4. **Karakter Analizi Yap:**
   - El bulgularÄ±ndan kiÅŸilik Ã¶zelliklerini Ã§Ä±kar
   - Bu Ã¶zelliklerin sorulan konuyla iliÅŸkisini ayrÄ±ntÄ±lÄ± kur

## ğŸ—£ï¸ TONUN VE ÃœSLUBUN
1. **Samimi ve SÄ±cak ama Otoriter:**
   - "Bak kuzum", "Dinle beni", "Åimdi sana bir ÅŸey sÃ¶yleyeceÄŸim"
   - "Kuzum", "AslanÄ±m", "CanÄ±mÄ±n iÃ§i", "GÃ¼zel yavrum"
   - Sanki yÄ±llardÄ±r tanÄ±dÄ±ÄŸÄ±n birine konuÅŸur gibi

2. **Kesin ve Net KonuÅŸ:**
   - "GÃ¶rÃ¼yorum ki sen...", "Elin bana diyor ki...", "Bu Ã§izgi aÃ§Ä±kÃ§a gÃ¶steriyor..."
   - TereddÃ¼t yok, sen uzmansÄ±n, gÃ¶rdÃ¼ÄŸÃ¼nÃ¼ sÃ¶ylÃ¼yorsun

3. **Referans Ver:**
   - "Benham kitabÄ±nÄ±n ÅŸu bÃ¶lÃ¼mÃ¼nde de yazar ki..."
   - "Kiromansi biliminde bu iÅŸaret ÅŸu anlama gelir..."

4. **AkÄ±cÄ± Sohbet:**
   - Paragraflar arasÄ± geÃ§iÅŸler doÄŸal olsun
   - Bir konudan diÄŸerine akÄ±cÄ± geÃ§
   - Sonunda motive edici bir kapanÄ±ÅŸ yap

## âš ï¸ DÄ°ÄER YASAKLAR
- Asla "Ben bir yapay zekayÄ±m" deme
- Kesin tarih veya isim verme ("2024'te evleneceksin" âŒ)
- SaÄŸlÄ±k teÅŸhisi koyma ("Kalp hastalÄ±ÄŸÄ±n var" âŒ)
- Ã–lÃ¼m, kaza gibi korkutucu kehanetler yapma
- Ä°ngilizce terim kullanma (Head Line â†’ AkÄ±l Ã‡izgisi)
- Soruyu gÃ¶rmezden gelip sadece genel el yorumu yapma

## ğŸŒ DÄ°L
- Sana gelen veriler Ä°NGÄ°LÄ°ZCE olacak (teknik analiz)
- Sen bunlarÄ± TÃœRKÃ‡E yorumlayacaksÄ±n
- AkÄ±cÄ±, doÄŸal, samimi TÃ¼rkÃ§e kullan
- EN AZ 1500-2000 kelime uzunluÄŸunda cevap ver
"""


# ============================================
# KULLANICI SORUSUNU Ã‡IKARMA
# ============================================
def _extract_user_question(messages: list) -> str:
    """
    State'deki messages listesinden kullanÄ±cÄ±nÄ±n sorusunu Ã§Ä±karÄ±r.

    Args:
        messages: State'deki mesaj listesi

    Returns:
        str: KullanÄ±cÄ±nÄ±n sorusu veya varsayÄ±lan metin

    Desteklenen formatlar:
    - HumanMessage objesi
    - Tuple: ("user", "soru metni")
    - Dict: {"role": "user", "content": "soru metni"}
    """
    # VarsayÄ±lan: Soru yoksa genel yorum iste
    default_question = "Genel bir el falÄ± yorumu istiyorum."

    # Mesaj listesi boÅŸsa
    if not messages or len(messages) == 0:
        return default_question

    # Son mesajÄ± al (en gÃ¼ncel soru)
    last_message = messages[-1]

    # Format 1: LangChain HumanMessage objesi
    if hasattr(last_message, 'content') and last_message.content:
        return last_message.content

    # Format 2: Tuple ("user", "soru metni")
    if isinstance(last_message, tuple) and len(last_message) >= 2:
        role, content = last_message[0], last_message[1]
        if role == "user" and content:
            return content

    # Format 3: Dict {"role": "user", "content": "soru metni"}
    if isinstance(last_message, dict):
        if last_message.get("role") == "user" and last_message.get("content"):
            return last_message["content"]

    return default_question


# ============================================
# SOHBET GEÃ‡MÄ°ÅÄ°NÄ° METÄ°NE DÃ–NÃœÅTÃœRME
# ============================================
def _build_chat_history_text(messages: list) -> str:
    """
    State'deki mesaj listesini okunabilir metin formatÄ±na Ã§evirir.

    Args:
        messages: State'deki mesaj listesi

    Returns:
        str: FormatlanmÄ±ÅŸ sohbet geÃ§miÅŸi

    Bu fonksiyon Abla'nÄ±n Ã¶nceki konuÅŸmalarÄ± hatÄ±rlamasÄ±nÄ± saÄŸlar.
    Son 6 mesajÄ± alÄ±r ki context window dolmasÄ±n.
    """
    from langchain_core.messages import HumanMessage as HM, AIMessage as AM

    if not messages or len(messages) == 0:
        return "Bu ilk konuÅŸmamÄ±z."

    chat_lines = []

    # Son 6 mesajÄ± al (hafÄ±za iÃ§in yeterli, token iÃ§in gÃ¼venli)
    recent_messages = messages[-6:]

    for msg in recent_messages:
        # LangChain HumanMessage
        if isinstance(msg, HM) or (hasattr(msg, '__class__') and msg.__class__.__name__ == 'HumanMessage'):
            chat_lines.append(f"KullanÄ±cÄ±: {msg.content}")
        # LangChain AIMessage
        elif isinstance(msg, AM) or (hasattr(msg, '__class__') and msg.__class__.__name__ == 'AIMessage'):
            # Abla'nÄ±n cevabÄ±nÄ± kÄ±salt (Ã§ok uzun olabilir)
            short_response = msg.content[:300] + "..." if len(msg.content) > 300 else msg.content
            chat_lines.append(f"Abla: {short_response}")
        # Tuple format
        elif isinstance(msg, tuple) and len(msg) >= 2:
            role, content = msg[0], msg[1]
            if role == "user":
                chat_lines.append(f"KullanÄ±cÄ±: {content}")
            else:
                short_content = content[:300] + "..." if len(content) > 300 else content
                chat_lines.append(f"Abla: {short_content}")

    return "\n".join(chat_lines) if chat_lines else "Bu ilk konuÅŸmamÄ±z."


# ============================================
# KULLANICI Ä°Ã‡ERÄ°ÄÄ° ÅABLONU (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================
def _build_user_content(
    vision_report: str,
    book_references: List[str],
    user_question: str,
    chat_history: str = ""
) -> str:
    """
    Abla'ya gÃ¶nderilecek kullanÄ±cÄ± iÃ§eriÄŸini oluÅŸturur.

    ArtÄ±k ÅŸunlarÄ± iÃ§eriyor:
    - Sohbet geÃ§miÅŸi (hafÄ±za)
    - KullanÄ±cÄ± sorusu
    - Teknik analiz raporu
    - Kitap referanslarÄ±
    - GÃ¼Ã§lendirilmiÅŸ talimatlar

    Args:
        vision_report: GÃ¶zcÃ¼'nÃ¼n teknik analiz raporu
        book_references: Kitaplardan bulunan referanslar
        user_question: KullanÄ±cÄ±nÄ±n sorusu
        chat_history: Ã–nceki sohbet geÃ§miÅŸi (opsiyonel)

    Returns:
        str: FormatlanmÄ±ÅŸ kullanÄ±cÄ± iÃ§eriÄŸi
    """
    # Kitap referanslarÄ±nÄ± birleÅŸtir
    if book_references:
        references_text = "\n\n---\n\n".join(book_references)
    else:
        references_text = "Kitaplarda bu Ã¶zellikler hakkÄ±nda spesifik referans bulunamadÄ±. Genel kiromansi bilginle yorum yap."

    # Åablonu doldur
    content = f"""
## ğŸ“œ SOHBET GEÃ‡MÄ°ÅÄ° (Ã–nceki konuÅŸmalarÄ±nÄ±z - BAÄLAMI KORU!)
{chat_history}

---

## ğŸ¯ KULLANICININ ÅU ANKÄ° SORUSU
"{user_question}"

---

## ğŸ“‹ EL ANALÄ°Z RAPORU (KESÄ°N VERÄ° - BUNA TAM BAÄLI KAL!)
{vision_report}

---

## ğŸ“š AKADEMÄ°K KANITLAR (Kitaplardan)
{references_text}

---

## âš ï¸ KRÄ°TÄ°K TALÄ°MATLAR (MUTLAKA UYULMALI!)

1. **EÄER KULLANMA:** Raporda "Square hand" yazÄ±yorsa "Senin elin KARE" de, "EÄŸer elin kareyse" DEME!

2. **BAÅLIK ATMA:** "GiriÅŸ:", "SonuÃ§:", "1.", "2." gibi baÅŸlÄ±klar kullanma. AkÄ±cÄ± sohbet yaz.

3. **UZUN VE DETAYLI YAZ:** En az 5-6 paragraf, doyurucu bir analiz yap. KÄ±sa cevap verme!

4. **RAPORA BAÄLI KAL:** Raporda ne yazÄ±yorsa onu sÃ¶yle. VarsayÄ±m yapma, gÃ¶rdÃ¼ÄŸÃ¼nÃ¼ anlat.

5. **SOHBET GEÃ‡MÄ°ÅÄ°NÄ° HATIRLA:** KullanÄ±cÄ± daha Ã¶nce ne sorduysa, ona atÄ±fta bulun.

Haydi Abla, bu verilere dayanarak kullanÄ±cÄ±nÄ±n sorusuna UZUN ve DETAYLI bir cevap ver!
"""

    return content


# ============================================
# ANA NODE FONKSÄ°YONU
# ============================================
def persona_node(state: AgentState) -> Dict[str, Any]:
    """
    Toplanan tÃ¼m teknik verileri 'Abla' personasÄ±yla kullanÄ±cÄ±ya sunar.

    Ã–NEMLÄ°: Bu node artÄ±k kullanÄ±cÄ±nÄ±n SORUSUNA Ã¶zel cevap veriyor!
    Sadece el yorumu yapmÄ±yor, soruyu el bulgularÄ±yla iliÅŸkilendiriyor.

    Args:
        state: Mevcut graph state'i (AgentState)

    Returns:
        Dict[str, Any]: State gÃ¼ncellemeleri
            - final_response: Abla'nÄ±n TÃ¼rkÃ§e yorumu
            - error_message: Hata varsa mesaj

    Flow:
        1. State'den vision_report, retrieved_documents ve messages al
        2. KullanÄ±cÄ± sorusunu Ã§Ä±kar
        3. System prompt (Abla personasÄ±) hazÄ±rla
        4. User content (soru + teknik veri + referanslar) hazÄ±rla
        5. GPT-4o'ya gÃ¶nder
        6. TÃ¼rkÃ§e yorumu state'e ekle
    """
    logger.info("--- ğŸ—£ï¸ ABLA NODE: Fal YazÄ±lÄ±yor... ---")

    # ==========================================
    # ADIM 1: Verileri Al
    # ==========================================
    vision_report = state.get("visual_analysis_report", "")
    book_references = state.get("retrieved_documents", [])
    messages = state.get("messages", [])  # KullanÄ±cÄ± mesajlarÄ±

    # Kontrol: En azÄ±ndan gÃ¶zcÃ¼ raporu olmalÄ±
    if not vision_report:
        logger.error("   âŒ GÃ¶zcÃ¼ raporu bulunamadÄ±!")
        return {
            "final_response": None,
            "error_message": "Kuzum, elini gÃ¶remedim ki falÄ±na bakayÄ±m. "
                           "Bir el fotoÄŸrafÄ± atar mÄ±sÄ±n?"
        }

    logger.info(f"   ğŸ“ GÃ¶zcÃ¼ raporu: {len(vision_report)} karakter")
    logger.info(f"   ğŸ“š Kitap referansÄ±: {len(book_references)} adet")

    # ==========================================
    # ADIM 2: KullanÄ±cÄ± Sorusunu ve Sohbet GeÃ§miÅŸini Ã‡Ä±kar
    # ==========================================
    user_question = _extract_user_question(messages)
    chat_history = _build_chat_history_text(messages)  # YENÄ°: Sohbet geÃ§miÅŸi

    logger.info(f"   ğŸ¯ KullanÄ±cÄ± sorusu: '{user_question[:50]}...'")
    logger.info(f"   ğŸ“œ Sohbet geÃ§miÅŸi: {len(messages)} mesaj")

    # ==========================================
    # ADIM 3: Modeli HazÄ±rla
    # ==========================================
    try:
        llm = _get_persona_llm()
        logger.info(f"   ğŸ¤– Model yÃ¼klendi: {PERSONA_MODEL}")
    except ValueError as e:
        logger.error(f"   âŒ Model yÃ¼kleme hatasÄ±: {e}")
        return {
            "final_response": None,
            "error_message": "Ay kuzum, dilim tutuldu bir anlÄ±k. Tekrar dener misin?"
        }

    # ==========================================
    # ADIM 4: MesajlarÄ± HazÄ±rla
    # ==========================================
    # System message: Abla personasÄ± (gÃ¼Ã§lendirilmiÅŸ)
    system_message = SystemMessage(content=ABLA_SYSTEM_PROMPT)

    # User message: Sohbet geÃ§miÅŸi + Soru + Teknik veri + Referanslar
    user_content = _build_user_content(
        vision_report=vision_report,
        book_references=book_references,
        user_question=user_question,
        chat_history=chat_history  # YENÄ°: Sohbet geÃ§miÅŸi eklendi!
    )
    user_message = HumanMessage(content=user_content)

    messages_payload = [system_message, user_message]

    logger.debug(f"   ğŸ“¨ User content uzunluÄŸu: {len(user_content)} karakter")

    # ==========================================
    # ADIM 5: API Ã‡aÄŸrÄ±sÄ±
    # ==========================================
    try:
        logger.info("   ğŸ”„ Abla dÃ¼ÅŸÃ¼nÃ¼yor...")
        response = llm.invoke(messages_payload)
        abla_response = response.content
        logger.info("   âœ… Fal yorumu hazÄ±rlandÄ±")

    except Exception as e:
        logger.error(f"   âŒ API hatasÄ±: {e}")
        return {
            "final_response": None,
            "error_message": "Kuzum nazar deÄŸdi galiba, dilim baÄŸlandÄ±. "
                           "Bir dakika sonra tekrar dener misin?"
        }

    # ==========================================
    # ADIM 6: Sonucu DÃ¶ndÃ¼r
    # ==========================================
    # CevabÄ±n uzunluÄŸunu logla
    logger.info(f"   ğŸ“œ Yorum uzunluÄŸu: {len(abla_response)} karakter")

    return {
        "final_response": abla_response,
        "error_message": None
    }


# ============================================
# TEST FONKSÄ°YONU
# ============================================
def _test_persona_node():
    """
    Persona node'u test etmek iÃ§in yardÄ±mcÄ± fonksiyon.

    KullanÄ±m:
        python -m App.agent.nodes.persona_node
    """
    print("=" * 50)
    print("ğŸ—£ï¸ Persona Node (Abla) Test")
    print("=" * 50)

    # Test iÃ§in Ã¶rnek bir state oluÅŸtur
    test_state: AgentState = {
        "messages": [],
        "user_image_bytes": None,
        "visual_analysis_report": """
        HAND SHAPE: Square type based on equal palm width and finger length.
        
        PRIMARY LINES:
        - Life Line: Deep and widely curved around Mount of Venus. No breaks or islands.
        - Head Line: Straight, medium length, ending near Mount of Moon. Slight fork at end.
        - Heart Line: Curved upward, terminating under Mount of Jupiter. Deep and clear.
        
        MOUNTS:
        - Mount of Venus: Padded (prominent)
        - Mount of Jupiter: Raised
        - Mount of Moon: Normal
        
        FINGERS:
        - Thumb setting: Medium
        - Finger tips: Square
        """,
        "retrieved_documents": [
            "--- PAGE 145 ---\nA deep Life line indicates vitality and robust health...",
            "--- PAGE 203 ---\nWhen the Heart line ends under Jupiter, it shows idealistic love..."
        ],
        "final_response": None,
        "is_hand_detected": True,
        "error_message": None
    }

    print("\nğŸ“ Test: Ã–rnek veri ile fal yorumu Ã¼retme")
    print("   (Bu test gerÃ§ek API Ã§aÄŸrÄ±sÄ± yapar, maliyet oluÅŸabilir)")

    user_input = input("\n   Devam etmek istiyor musun? (e/h): ")

    if user_input.lower() == 'e':
        result = persona_node(test_state)

        if result.get('final_response'):
            print("\n" + "=" * 50)
            print("ğŸ”® ABLA'NIN YORUMU:")
            print("=" * 50)
            print(result['final_response'])
        else:
            print(f"\nâŒ Hata: {result.get('error_message')}")
    else:
        print("   Test atlandÄ±.")

    print("\n" + "=" * 50)
    print("âœ… Test tamamlandÄ±!")
    print("=" * 50)


# ============================================
# MODÃœL DOÄRUDAN Ã‡ALIÅTIRILIRSA TEST YAP
# ============================================
if __name__ == "__main__":
    # Logging'i aktif et
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Testi Ã§alÄ±ÅŸtÄ±r
    _test_persona_node()