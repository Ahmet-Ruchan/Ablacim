"""
============================================
Boncuk VISION - Persona Node (Abla)
============================================
Bu dÃ¼ÄŸÃ¼m, toplanan tÃ¼m verileri alÄ±r ve
"Boncuk Abla" personasÄ± ile kullanÄ±cÄ±ya sunar.

GÃ¶rev:
- GÃ¶zcÃ¼'nÃ¼n teknik raporunu al
- AraÅŸtÄ±rmacÄ±'nÄ±n kitap referanslarÄ±nÄ± al
- BunlarÄ± sÄ±cak, samimi "Abla" Ã¼slubuyla yorumla
- TÃ¼rkÃ§e cevap Ã¼ret

Persona Ã–zellikleri:
- SÄ±cak ve samimi ("Kuzum", "AslanÄ±m", "CanÄ±m")
- Bilgili ama ulaÅŸÄ±labilir
- SandviÃ§ TekniÄŸi: Ã–vgÃ¼ â†’ UyarÄ± â†’ Motivasyon
- ReferanslÄ± (Kitaplardan alÄ±ntÄ± yapar)

Yazar: Ahmet RuÃ§han
Tarih: 2024
============================================
"""

# ============================================
# IMPORTS - Gerekli KÃ¼tÃ¼phaneler
# ============================================
import os  # Environment deÄŸiÅŸkenleri iÃ§in
import logging  # Profesyonel loglama
from typing import Dict, Any, List  # Type hints iÃ§in

from dotenv import load_dotenv  # .env dosyasÄ± okuma
from langchain_openai import ChatOpenAI  # GPT-4o modeli
from langchain_core.messages import (  # Mesaj formatlarÄ±
    SystemMessage,
    HumanMessage
)

# Kendi modÃ¼llerimiz
from app.agent.state import AgentState

# ============================================
# LOGGING AYARLARI
# ============================================
# Bu modÃ¼l iÃ§in Ã¶zel logger oluÅŸtur
logger = logging.getLogger(__name__)

# ============================================
# ENVIRONMENT DEÄÄ°ÅKENLERÄ°
# ============================================
# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# --- API AnahtarÄ± ---
OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")

# --- Model AyarlarÄ± ---
PERSONA_MODEL: str = os.getenv("VISION_MODEL", "gpt-4o")  # AynÄ± model
PERSONA_MAX_TOKENS: int = int(os.getenv("PERSONA_MAX_TOKENS", "1500"))
"""
PERSONA_MAX_TOKENS: Abla'nÄ±n cevap uzunluÄŸu
- 1000: KÄ±sa, Ã¶z yorumlar
- 1500: Orta detay (Ã¶nerilen)
- 2000: Uzun, detaylÄ± fallar
"""


# ============================================
# MODEL BAÅLATMA
# ============================================
def _get_persona_llm() -> ChatOpenAI:
    """
    Abla persona iÃ§in GPT-4o modelini baÅŸlatÄ±r.

    Returns:
        ChatOpenAI: YapÄ±landÄ±rÄ±lmÄ±ÅŸ model instance'Ä±

    Raises:
        ValueError: API key eksikse
    """
    if not OPENAI_API_KEY:
        raise ValueError("âŒ OPENAI_API_KEY .env dosyasÄ±nda bulunamadÄ±!")

    return ChatOpenAI(
        model=PERSONA_MODEL,
        api_key=OPENAI_API_KEY,
        max_tokens=PERSONA_MAX_TOKENS,
        temperature=0.8  # Biraz yaratÄ±cÄ±lÄ±k iÃ§in
    )


# ============================================
# ABLA PERSONA PROMPT'U
# ============================================
ABLA_SYSTEM_PROMPT: str = """
Sen 'Boncuk Abla'sÄ±n. Geleneksel TÃ¼rk falcÄ± aÄŸzÄ±yla konuÅŸan, hem mistik hem de bilimsel el falÄ± (Kiromansi) bilen bir yapay zeka asistanÄ±sÄ±n.

## ğŸ­ KÄ°MLÄ°ÄÄ°N
- AdÄ±n: Boncuk Abla
- UzmanlÄ±k: Kiromansi (El FalÄ±), Ã¶zellikle Benham ve St. Germain ekolÃ¼
- Deneyim: YÄ±llardÄ±r el okuyan, binlerce ele bakan tecrÃ¼beli bir falcÄ±

## ğŸ—£ï¸ TONUN VE ÃœSLUBUN
1. **Samimi ve SÄ±cak:**
   - "Kuzum", "AslanÄ±m", "CanÄ±mÄ±n iÃ§i", "GÃ¼zel yavrum" gibi hitaplar kullan
   - Mesafeli deÄŸil, sanki karÅŸÄ±nda tanÄ±dÄ±ÄŸÄ±n biri varmÄ±ÅŸ gibi konuÅŸ

2. **Bilgili ama UlaÅŸÄ±labilir:**
   - Teknik terimleri kullan ama aÃ§Ä±kla
   - "Hayat Ã§izgin" de, "Life Line" deme
   - Kitaplardan referans ver: "Benham kitabÄ±nda da yazar ki..."

3. **SandviÃ§ TekniÄŸi (Ã–NEMLÄ°!):**
   - ğŸ Ã–NCE: GÃ¼zel bir Ã¶zelliÄŸinden bahset (Ã¶vgÃ¼)
   - ğŸ¥¬ SONRA: Dikkat etmesi gereken noktayÄ± sÃ¶yle (uyarÄ±)
   - ğŸ EN SON: Motive edici bir cÃ¼mleyle bitir (umut)

4. **Dobra ama KÄ±rÄ±cÄ± DeÄŸil:**
   - KÃ¶tÃ¼ bir ÅŸey gÃ¶rsen bile yÄ±kÄ±cÄ± olma
   - "Åurada biraz zorluk var ama..." ÅŸeklinde yumuÅŸat
   - Asla "BaÅŸÄ±na kÃ¶tÃ¼ ÅŸeyler gelecek" gibi kehanetlerde bulunma

5. **Mistik Hava:**
   - Ara sÄ±ra "MaÅŸallah", "Ä°nÅŸallah", "Allah korusun" gibi ifadeler kullan
   - Ama batÄ±l inanÃ§lara deÄŸil, gÃ¶zleme dayalÄ± konuÅŸ

## âš ï¸ YAPMAMAN GEREKENLER
- Asla "Ben bir yapay zekayÄ±m" deme
- Kesin tarih veya isim verme ("2024'te evleneceksin" âŒ)
- SaÄŸlÄ±k teÅŸhisi koyma ("Kalp hastalÄ±ÄŸÄ±n var" âŒ)
- Ã–lÃ¼m, kaza gibi korkutucu kehanetler yapma
- Ä°ngilizce terim kullanma (Head Line â†’ AkÄ±l Ã‡izgisi)

## ğŸ“ CEVAP FORMATI
1. KÄ±sa bir selamlama
2. Elin genel deÄŸerlendirmesi (el tipi)
3. Ã‡izgilerin yorumu (en az 3 ana Ã§izgi)
4. Tepelerin/daÄŸlarÄ±n yorumu
5. Genel deÄŸerlendirme ve tavsiyeler
6. Motive edici kapanÄ±ÅŸ

## ğŸŒ DÄ°L
- Sana gelen veriler Ä°NGÄ°LÄ°ZCE olacak (teknik analiz)
- Sen bunlarÄ± TÃœRKÃ‡E yorumlayacaksÄ±n
- AkÄ±cÄ±, doÄŸal TÃ¼rkÃ§e kullan
"""


# ============================================
# KULLANICI Ä°Ã‡ERÄ°ÄÄ° ÅABLONU
# ============================================
def _build_user_content(
        vision_report: str,
        book_references: List[str]
) -> str:
    """
    Abla'ya gÃ¶nderilecek kullanÄ±cÄ± iÃ§eriÄŸini oluÅŸturur.

    Args:
        vision_report: GÃ¶zcÃ¼'nÃ¼n teknik analiz raporu
        book_references: Kitaplardan bulunan referanslar

    Returns:
        str: FormatlanmÄ±ÅŸ kullanÄ±cÄ± iÃ§eriÄŸi
    """
    # Kitap referanslarÄ±nÄ± birleÅŸtir
    if book_references:
        references_text = "\n\n---\n\n".join(book_references)
    else:
        references_text = "Kitaplarda bu Ã¶zellikler hakkÄ±nda spesifik bir referans bulunamadÄ±. Genel bilginle yorum yap."

    # Åablonu doldur
    content = f"""
## ğŸ“‹ GÃ–ZCÃœ'NÃœN TEKNÄ°K ANALÄ°ZÄ° (Ä°ngilizce)
{vision_report}

## ğŸ“š KÄ°TAPLARDAN BULUNAN REFERANSLAR
{references_text}

---

YukarÄ±daki teknik verileri ve kitap referanslarÄ±nÄ± kullanarak, bu kiÅŸinin elini Boncuk Abla olarak yorumla.
SandviÃ§ tekniÄŸini unutma: Ã–vgÃ¼ â†’ UyarÄ± â†’ Motivasyon
"""

    return content


# ============================================
# ANA NODE FONKSÄ°YONU
# ============================================
def persona_node(state: AgentState) -> Dict[str, Any]:
    """
    Toplanan tÃ¼m teknik verileri 'Abla' personasÄ±yla kullanÄ±cÄ±ya sunar.

    Bu fonksiyon LangGraph tarafÄ±ndan Ã§aÄŸrÄ±lÄ±r.
    GÃ¶zcÃ¼ raporu ve kitap referanslarÄ±nÄ± alÄ±r,
    sÄ±cak ve samimi bir TÃ¼rkÃ§e yorum Ã¼retir.

    Args:
        state: Mevcut graph state'i (AgentState)

    Returns:
        Dict[str, Any]: State gÃ¼ncellemeleri
            - final_response: Abla'nÄ±n TÃ¼rkÃ§e yorumu
            - error_message: Hata varsa mesaj

    Flow:
        1. State'den vision_report ve retrieved_documents al
        2. System prompt (Abla personasÄ±) hazÄ±rla
        3. User content (teknik veri + referanslar) hazÄ±rla
        4. GPT-4o'ya gÃ¶nder
        5. TÃ¼rkÃ§e yorumu state'e ekle
    """
    logger.info("--- ğŸ—£ï¸ ABLA NODE: Fal YazÄ±lÄ±yor... ---")

    # ==========================================
    # ADIM 1: Verileri Al
    # ==========================================
    vision_report = state.get("visual_analysis_report", "")
    book_references = state.get("retrieved_documents", [])

    # Kontrol: En azÄ±ndan gÃ¶zcÃ¼ raporu olmalÄ±
    if not vision_report:
        logger.error("   âŒ GÃ¶zcÃ¼ raporu bulunamadÄ±!")
        return {
            "final_response": None,
            "error_message": "Kuzum, elini gÃ¶remedim ki falÄ±na bakayÄ±m. "
                             "Bir el fotoÄŸrafÄ± atar mÄ±sÄ±n?"
        }

    logger.info(f"   ğŸ“ GÃ¶zcÃ¼ raporu: {len(vision_report)} karakter")
    logger.info(f"   ğŸ“š Kitap referansÄ±: {len(book_references)} adet")

    # ==========================================
    # ADIM 2: Modeli HazÄ±rla
    # ==========================================
    try:
        llm = _get_persona_llm()
        logger.info(f"   ğŸ¤– Model yÃ¼klendi: {PERSONA_MODEL}")
    except ValueError as e:
        logger.error(f"   âŒ Model yÃ¼kleme hatasÄ±: {e}")
        return {
            "final_response": None,
            "error_message": "Ay kuzum, dilim tutuldu bir anlÄ±k. Tekrar dener misin?"
        }

    # ==========================================
    # ADIM 3: MesajlarÄ± HazÄ±rla
    # ==========================================
    # System message: Abla personasÄ±
    system_message = SystemMessage(content=ABLA_SYSTEM_PROMPT)

    # User message: Teknik veri + Referanslar
    user_content = _build_user_content(vision_report, book_references)
    user_message = HumanMessage(content=user_content)

    messages = [system_message, user_message]

    logger.debug(f"   ğŸ“¨ User content uzunluÄŸu: {len(user_content)} karakter")

    # ==========================================
    # ADIM 4: API Ã‡aÄŸrÄ±sÄ±
    # ==========================================
    try:
        logger.info("   ğŸ”„ Abla dÃ¼ÅŸÃ¼nÃ¼yor...")
        response = llm.invoke(messages)
        abla_response = response.content
        logger.info("   âœ… Fal yorumu hazÄ±rlandÄ±")

    except Exception as e:
        logger.error(f"   âŒ API hatasÄ±: {e}")
        return {
            "final_response": None,
            "error_message": "Kuzum nazar deÄŸdi galiba, dilim baÄŸlandÄ±. "
                             "Bir dakika sonra tekrar dener misin?"
        }

    # ==========================================
    # ADIM 5: Sonucu DÃ¶ndÃ¼r
    # ==========================================
    # CevabÄ±n uzunluÄŸunu logla
    logger.info(f"   ğŸ“œ Yorum uzunluÄŸu: {len(abla_response)} karakter")

    return {
        "final_response": abla_response,
        "error_message": None
    }


# ============================================
# TEST FONKSÄ°YONU
# ============================================
def _test_persona_node():
    """
    Persona node'u test etmek iÃ§in yardÄ±mcÄ± fonksiyon.

    KullanÄ±m:
        python -m App.agent.nodes.persona_node
    """
    print("=" * 50)
    print("ğŸ—£ï¸ Persona Node (Abla) Test")
    print("=" * 50)

    # Test iÃ§in Ã¶rnek bir state oluÅŸtur
    test_state: AgentState = {
        "messages": [],
        "user_image_bytes": None,
        "visual_analysis_report": """
        HAND SHAPE: Square type based on equal palm width and finger length.

        PRIMARY LINES:
        - Life Line: Deep and widely curved around Mount of Venus. No breaks or islands.
        - Head Line: Straight, medium length, ending near Mount of Moon. Slight fork at end.
        - Heart Line: Curved upward, terminating under Mount of Jupiter. Deep and clear.

        MOUNTS:
        - Mount of Venus: Padded (prominent)
        - Mount of Jupiter: Raised
        - Mount of Moon: Normal

        FINGERS:
        - Thumb setting: Medium
        - Finger tips: Square
        """,
        "retrieved_documents": [
            "--- PAGE 145 ---\nA deep Life line indicates vitality and robust health...",
            "--- PAGE 203 ---\nWhen the Heart line ends under Jupiter, it shows idealistic love..."
        ],
        "final_response": None,
        "is_hand_detected": True,
        "error_message": None
    }

    print("\nğŸ“ Test: Ã–rnek veri ile fal yorumu Ã¼retme")
    print("   (Bu test gerÃ§ek API Ã§aÄŸrÄ±sÄ± yapar, maliyet oluÅŸabilir)")

    user_input = input("\n   Devam etmek istiyor musun? (e/h): ")

    if user_input.lower() == 'e':
        result = persona_node(test_state)

        if result.get('final_response'):
            print("\n" + "=" * 50)
            print("ğŸ”® ABLA'NIN YORUMU:")
            print("=" * 50)
            print(result['final_response'])
        else:
            print(f"\nâŒ Hata: {result.get('error_message')}")
    else:
        print("   Test atlandÄ±.")

    print("\n" + "=" * 50)
    print("âœ… Test tamamlandÄ±!")
    print("=" * 50)


# ============================================
# MODÃœL DOÄRUDAN Ã‡ALIÅTIRILIRSA TEST YAP
# ============================================
if __name__ == "__main__":
    # Logging'i aktif et
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Testi Ã§alÄ±ÅŸtÄ±r
    _test_persona_node()