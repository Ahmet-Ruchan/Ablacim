"""
============================================
YASAA VISION - Vision Analysis Node (GÃ¶zcÃ¼)
============================================
Bu dÃ¼ÄŸÃ¼m, kullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi el fotoÄŸrafÄ±nÄ±
GPT-4o Vision modeli ile analiz eder.

GÃ¶rev:
- FotoÄŸrafÄ±n el olup olmadÄ±ÄŸÄ±nÄ± kontrol et
- El ise teknik analiz yap (Ã§izgiler, tepeler, parmaklar)
- Kesinlikle YORUM yapma, sadece GÃ–ZLEM yap

Ã‡Ä±ktÄ±:
- is_hand_detected: El tespit edildi mi?
- visual_analysis_report: Teknik analiz raporu

Yazar: Ahmet RuÃ§han
Tarih: 2024
============================================
"""

# ============================================
# IMPORTS - Gerekli KÃ¼tÃ¼phaneler
# ============================================
import os                                      # Environment deÄŸiÅŸkenleri iÃ§in
import logging                                 # Profesyonel loglama
from typing import Dict, Any                   # Type hints iÃ§in

from dotenv import load_dotenv                 # .env dosyasÄ± okuma
from langchain_openai import ChatOpenAI        # GPT-4o modeli
from langchain_core.messages import HumanMessage  # Mesaj formatÄ±

# Kendi modÃ¼llerimiz
from App.agent.state import AgentState


# ============================================
# LOGGING AYARLARI
# ============================================
# Bu modÃ¼l iÃ§in Ã¶zel logger oluÅŸtur
logger = logging.getLogger(__name__)


# ============================================
# ENVIRONMENT DEÄÄ°ÅKENLERÄ°
# ============================================
# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

import streamlit as st
def get_secret(name: str):
    return st.secrets.get(name) or os.getenv(name)


# --- API AnahtarÄ± ---
OPENAI_API_KEY: str = get_secret("OPENAI_API_KEY")

# --- Model AyarlarÄ± ---
VISION_MODEL: str = os.getenv("VISION_MODEL", "gpt-4o")
VISION_MAX_TOKENS: int = int(os.getenv("VISION_MAX_TOKENS", "1000"))


# ============================================
# MODEL BAÅLATMA
# ============================================
def _get_vision_llm() -> ChatOpenAI:
    """
    GPT-4o Vision modelini baÅŸlatÄ±r.

    Returns:
        ChatOpenAI: YapÄ±landÄ±rÄ±lmÄ±ÅŸ model instance'Ä±

    Raises:
        ValueError: API key eksikse
    """
    if not OPENAI_API_KEY:
        raise ValueError("âŒ OPENAI_API_KEY .env dosyasÄ±nda bulunamadÄ±!")

    return ChatOpenAI(
        model=VISION_MODEL,           # gpt-4o (vision destekli)
        api_key=OPENAI_API_KEY,       # API anahtarÄ±
        max_tokens=VISION_MAX_TOKENS  # Maksimum Ã§Ä±ktÄ± uzunluÄŸu
    )


# ============================================
# VISION PROMPT ÅABLONU (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å)
# ============================================
# Bu prompt GPT-4o'ya "neye bakacaÄŸÄ±nÄ±" ve
# NASIL ifade edeceÄŸini sÃ¶yler
# DÄ°KKAT: Kesin ifadeler kullan, "eÄŸer/belki" YASAK!
VISION_ANALYSIS_PROMPT: str = """
**ROLE:** Expert Chiromancy (Palmistry) Morphologist with 30 years of experience.

**TASK:** Analyze the provided hand image and generate a HIGHLY DETAILED, DEFINITIVE technical report.

**STRICT LANGUAGE RULES (CRITICAL!):**
1. **BE 100% DEFINITIVE:** Do NOT use uncertain words like:
   - âŒ "appears to be", "might be", "looks like", "seems", "possibly", "could be", "if"
   - âœ… Use "IS", "ARE", "HAS", "SHOWS" - speak with absolute certainty
   - BAD: "The fingers appear to be conic shaped."
   - GOOD: "The fingers ARE Conic shaped with smooth, rounded tips and tapered ends."

2. **MAXIMUM DETAIL:** Do not just list features. Describe:
   - Exact measurements relative to palm
   - Texture and skin quality
   - Depth and width of every line
   - Specific angles and curves
   - Color variations if visible

3. **NO INTERPRETATIONS:** Only physical descriptions. No meanings, no advice.

**COMPREHENSIVE ANALYSIS CHECKLIST:**

## 1. HAND SHAPE (Be specific about WHY)
- Exact classification: Square, Spatulate, Philosophic, Conic, Psychic, Elementary, or Mixed
- Palm width compared to length (ratio)
- Overall hand size relative to body (if visible)
- Flesh consistency: Soft/Flabby, Medium/Elastic, Hard/Firm

## 2. FINGERS (Each finger individually)
- **Length:** Relative to palm length, relative to each other
- **Tip Shapes:** Square, Pointed/Conic, Spatulate, Mixed
- **Joints:** Smooth or Knotty (Philosophic knots vs Practical knots)
- **Setting on Palm:** Even line, arch shape, or irregular
- **Spaces Between:** When held naturally - wide gaps or close together
- **THUMB (Critical):**
  - Setting: High, Medium, or Low on palm
  - Flexibility: Stiff (unbending) or Supple (bends back easily)
  - First Phalange (Will) vs Second Phalange (Logic) ratio
  - Angle of opening from hand

## 3. MAJOR LINES (Extremely detailed)

**LIFE LINE:**
- Starting point: Exact location between thumb and index finger
- Path: Close to thumb, wide curve around Venus, or moderate
- Ending point: Where exactly does it terminate?
- Depth: Deep/Medium/Faint/Chained
- Width: Broad or Fine
- Special Marks: Islands, breaks, chains, branches, crosses, stars
- Sister Line present? (Mars Line)

**HEAD LINE:**
- Starting point: Joined with Life Line? Separated? How much gap?
- Direction: Straight across palm, sloping toward Moon, or rising
- Length: Reaches Mercury? Stops at Apollo? Short?
- Ending: Clean end, fork (Writer's Fork), multiple branches
- Depth and clarity throughout its length
- Special marks: Islands (concentration issues), breaks, chains

**HEART LINE:**
- Starting point: Under Mercury finger
- Termination: Under Jupiter, between Jupiter-Saturn, under Saturn, or forked
- Curvature: Straight, curved upward, deeply curved
- Depth: Deep (passionate), Medium, Faint (reserved)
- Branches: Upward branches, downward branches, clean
- Girdle of Venus present above it?

**FATE LINE (if present):**
- Starting point: Wrist, Life Line, Moon mount, or middle of palm
- Path: Straight, curved, broken, multiple lines
- Ending point: Saturn, Jupiter, or other

## 4. MOUNTS (Rate each: Flat/Normal/Raised/Padded/Overdeveloped)
- **Venus** (base of thumb): Size, firmness, boundaries
- **Jupiter** (under index): Elevation, size
- **Saturn** (under middle): Presence, development
- **Apollo/Sun** (under ring): Prominence
- **Mercury** (under little): Development
- **Moon/Luna** (opposite thumb, lower): Size, padding
- **Mars Positive** (under Jupiter, inner palm)
- **Mars Negative** (under Mercury, inner palm)
- **Plain of Mars** (center of palm): Hollow or filled

## 5. SKIN TEXTURE & ADDITIONAL FEATURES
- Skin quality: Fine/Silky, Medium, Coarse/Rough
- Line density: Many fine lines (sensitive) or few main lines (simple nature)
- Color: Pink, pale, red, yellow tones
- Nails (if visible): Shape, moons, ridges

**OUTPUT FORMAT:**
Write a DENSE, CONTINUOUS technical narrative of approximately 400-500 words.
Do NOT use bullet points or headers in your output.
Write it as flowing professional prose, as if dictating a medical report.
Every statement must be DEFINITIVE - you are the expert, speak with authority.

**IMPORTANT - HAND DETECTION RULES:**
- ONLY respond with "NOT_A_HAND" if the image clearly shows something completely different (like a car, building, animal, text document)
- If you can see ANY hand or palm features AT ALL, even partially or at an angle, PROCEED WITH ANALYSIS
- If image quality is poor but it's a hand, do your best and note "LOW_QUALITY" at the start
- When in doubt, ANALYZE - err on the side of providing analysis rather than rejecting
- Hands photographed at angles, with objects in background, or partially visible should still be analyzed
"""


# ============================================
# ANA NODE FONKSÄ°YONU
# ============================================
def vision_analysis_node(state: AgentState) -> Dict[str, Any]:
    """
    KullanÄ±cÄ±nÄ±n gÃ¶nderdiÄŸi el fotoÄŸrafÄ±nÄ± analiz eder.

    Bu fonksiyon LangGraph tarafÄ±ndan Ã§aÄŸrÄ±lÄ±r.
    State'i alÄ±r, gÃ¶rsel analiz yapar, sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r.

    Args:
        state: Mevcut graph state'i (AgentState)

    Returns:
        Dict[str, Any]: State gÃ¼ncellemeleri
            - is_hand_detected: El tespit edildi mi?
            - visual_analysis_report: Teknik rapor (veya None)
            - error_message: Hata mesajÄ± (veya None)

    Flow:
        1. State'den resim verisini al
        2. Resim yoksa atla
        3. GPT-4o'ya gÃ¶nder
        4. Sonucu parse et
        5. State gÃ¼ncellemelerini dÃ¶ndÃ¼r
    """
    logger.info("--- ğŸ‘ï¸ GÃ–ZCÃœ NODE: FotoÄŸraf Analiz Ediliyor... ---")

    # ==========================================
    # ADIM 1: Resim Verisini Al
    # ==========================================
    image_data = state.get("user_image_bytes")

    # Resim yoksa - kullanÄ±cÄ± sadece sohbet ediyor olabilir
    if not image_data:
        logger.warning("   âš ï¸ Resim bulunamadÄ±, gÃ¶rsel analiz atlanÄ±yor.")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": None  # Bu bir hata deÄŸil, sadece resim yok
        }

    logger.info(f"   ğŸ“¸ Resim verisi alÄ±ndÄ± ({len(image_data)} karakter)")

    # ==========================================
    # ADIM 2: GPT-4o Vision'Ä± HazÄ±rla
    # ==========================================
    try:
        llm = _get_vision_llm()
        logger.info(f"   ğŸ¤– Model yÃ¼klendi: {VISION_MODEL}")
    except ValueError as e:
        logger.error(f"   âŒ Model yÃ¼kleme hatasÄ±: {e}")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": "Sistem hatasÄ± oluÅŸtu, lÃ¼tfen tekrar deneyin."
        }

    # ==========================================
    # ADIM 3: MesajÄ± HazÄ±rla ve GÃ¶nder
    # ==========================================
    # LangChain formatÄ±nda multimodal mesaj oluÅŸtur
    message = HumanMessage(
        content=[
            # Metin kÄ±smÄ±: Prompt
            {
                "type": "text",
                "text": VISION_ANALYSIS_PROMPT
            },
            # GÃ¶rsel kÄ±smÄ±: Base64 encoded resim
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{image_data}"
                }
            },
        ]
    )

    # ==========================================
    # ADIM 4: API Ã‡aÄŸrÄ±sÄ±
    # ==========================================
    try:
        logger.info("   ğŸ”„ GPT-4o Vision API Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±yor...")
        response = llm.invoke([message])
        analysis = response.content
        logger.info("   âœ… API yanÄ±tÄ± alÄ±ndÄ±")

    except Exception as e:
        # API hatasÄ± (rate limit, network, vb.)
        logger.error(f"   âŒ Vision API hatasÄ±: {e}")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": "FotoÄŸrafÄ± analiz edemedim, tekrar dener misin kuzum?"
        }

    # ==========================================
    # ADIM 5: Sonucu DeÄŸerlendir
    # ==========================================

    # Durum 1: El deÄŸil - SADECE cevap Ã§ok kÄ±sa ve NOT_A_HAND iÃ§eriyorsa
    # Bu, model'in uzun bir analizde bu kelimeyi kullanmasÄ±nÄ± engelliyor
    analysis_stripped = analysis.strip()
    is_rejection = (
        "NOT_A_HAND" in analysis_stripped and
        len(analysis_stripped) < 100  # KÄ±sa cevaplar = gerÃ§ek red
    )

    if is_rejection:
        logger.warning("   âŒ GÃ¶nderilen fotoÄŸraf el deÄŸil")
        return {
            "is_hand_detected": False,
            "visual_analysis_report": None,
            "error_message": "Kuzum bu el fotoÄŸrafÄ± deÄŸil gibi gÃ¶rÃ¼nÃ¼yor. "
                           "AvuÃ§ iÃ§ini dÃ¼zgÃ¼nce gÃ¶steren bir fotoÄŸraf atar mÄ±sÄ±n?"
        }

    # Durum 2: DÃ¼ÅŸÃ¼k kalite ama el
    if "LOW_QUALITY" in analysis:
        logger.warning("   âš ï¸ DÃ¼ÅŸÃ¼k kaliteli el fotoÄŸrafÄ±")
        # Yine de analize devam et, ama not dÃ¼ÅŸ
        analysis = analysis + "\n\n[NOT: FotoÄŸraf kalitesi dÃ¼ÅŸÃ¼k, analiz kÄ±sÄ±tlÄ± olabilir]"

    # Durum 3: BaÅŸarÄ±lÄ± analiz
    logger.info("   âœ… El fotoÄŸrafÄ± baÅŸarÄ±yla analiz edildi")
    logger.debug(f"   ğŸ“ Analiz Ã¶nizleme: {analysis[:200]}...")

    return {
        "is_hand_detected": True,
        "visual_analysis_report": analysis,
        "error_message": None
    }


# ============================================
# TEST FONKSÄ°YONU
# ============================================
def _test_vision_node():
    """
    Vision node'u test etmek iÃ§in yardÄ±mcÄ± fonksiyon.

    KullanÄ±m:
        python -m App.agent.nodes.vision_node
    """
    import base64

    print("=" * 50)
    print("ğŸ‘ï¸ Vision Node Test")
    print("=" * 50)

    # Test iÃ§in Ã¶rnek bir state oluÅŸtur (resim olmadan)
    test_state: AgentState = {
        "messages": [],
        "user_image_bytes": None,  # Test iÃ§in resim yok
        "visual_analysis_report": None,
        "retrieved_documents": [],
        "final_response": None,
        "is_hand_detected": False,
        "error_message": None
    }

    print("\nğŸ“ Test 1: Resim olmadan Ã§aÄŸÄ±r")
    result = vision_analysis_node(test_state)
    print(f"   SonuÃ§: {result}")

    print("\n" + "=" * 50)
    print("âœ… Test tamamlandÄ±!")
    print("=" * 50)
    print("\nğŸ’¡ GerÃ§ek bir el fotoÄŸrafÄ± ile test etmek iÃ§in:")
    print("   1. Bir el fotoÄŸrafÄ±nÄ± base64'e Ã§evirin")
    print("   2. test_state['user_image_bytes'] = base64_data")
    print("   3. vision_analysis_node(test_state) Ã§aÄŸÄ±rÄ±n")


# ============================================
# MODÃœL DOÄRUDAN Ã‡ALIÅTIRILIRSA TEST YAP
# ============================================
if __name__ == "__main__":
    # Logging'i aktif et
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Testi Ã§alÄ±ÅŸtÄ±r
    _test_vision_node()